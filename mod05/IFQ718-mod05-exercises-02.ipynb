{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9a8c80-3ff6-44c1-8ac5-494fb2194abc",
   "metadata": {},
   "source": [
    "# üõ† IFQ718 Module 05 Exercises 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d9e23-97a4-4243-be73-54340a97a430",
   "metadata": {
    "tags": []
   },
   "source": [
    "## üîç  Context: Tabular data with Pandas\n",
    "\n",
    "\n",
    "This will be our first notebook on the Pandas section of IFQ718. \n",
    "\n",
    "> pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with ‚Äúrelational‚Äù or ‚Äúlabeled‚Äù data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real-world data analysis in Python. Additionally, it has the broader goal of becoming the most powerful and flexible open source data analysis/manipulation tool available in any language. It is already well on its way toward this goal.\n",
    ">\n",
    "> Source: [Pandas reference manual](https://pandas.pydata.org/docs/getting_started/overview.htmlV)\n",
    "\n",
    "Pandas provides many convenient functions to apply to highly structured data. Your learnings of the Python Standard Libraries are going to be greatly complemented by the functionality of Pandas. You may quickly discover that the tasks you have been working on using vanilla Python can be achieved with less code when using Pandas. This is because the work of many open source [contributors](https://github.com/pandas-dev/pandas/graphs/contributors) has resulted in a fantastic tool that saves you time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a8a8a3-47e5-4f22-8cfa-123d1b3a405f",
   "metadata": {},
   "source": [
    "## Tabular data with Python\n",
    "\n",
    "In module 3, we tasked you with converting a CSV file to a table-like data structure in Python, specifically, a dictionary, where\n",
    "\n",
    "* the dictionary keys were the column labels of the table\n",
    "* the dictionary values were lists, containing the values of the table columns\n",
    "\n",
    "<pre>\n",
    "sepal_length,sepal_width,petal_length,petal_width,species\n",
    "4.4,3.0,1.3,0.2,setosa\n",
    "5.1,3.4,1.5,0.2,setosa\n",
    "5.0,3.5,1.3,0.3,setosa\n",
    "4.5,2.3,1.3,0.3,setosa\n",
    "4.4,3.2,1.3,0.2,setosa\n",
    "5.8,2.6,4.0,1.2,versicolor\n",
    "5.0,2.3,3.3,1.0,versicolor\n",
    "5.6,2.7,4.2,1.3,versicolor\n",
    "5.7,3.0,4.2,1.2,versicolor\n",
    "5.7,2.9,4.2,1.3,versicolor\n",
    "6.3,3.3,6.0,2.5,virginica\n",
    "6.8,3.2,5.9,2.3,virginica\n",
    "6.7,3.3,5.7,2.5,virginica\n",
    "6.7,3.0,5.2,2.3,virginica\n",
    "6.3,2.5,5.0,1.9,virginica\n",
    "</pre>\n",
    "\n",
    "Your dictionary had the following structure:\n",
    "\n",
    "```python\n",
    "iris_dataset = {\n",
    "    'sepal_length' : [4.4, 5.1, 5.0, 4.5, 4.4, 5.8, 5.0, 5.6, 5.7, 5.7, 6.3, 6.8, 6.7, 6.7, 6.3],\n",
    "    'sepal_width' : [3.0, 3.4, 3.5, 2.3, 3.2, 2.6, 2.3, 2.7, 3.0, 2.9, 3.3, 3.2, 3.3, 3.0, 2.5],\n",
    "    'petal_length' : [1.3, 1.5, 1.3, 1.3, 1.3, 4.0, 3.3, 4.2, 4.2, 4.2, 6.0, 5.9, 5.7, 5.2, 5.0],\n",
    "    'petal_width' : [0.2, 0.2, 0.3, 0.3, 0.2, 1.2, 1.0, 1.3, 1.2, 1.3, 2.5, 2.3, 2.5, 2.3, 1.9],\n",
    "    'species' : [\n",
    "            'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'versicolor', \n",
    "            'versicolor', 'versicolor', 'versicolor', 'versicolor', 'virginica', \n",
    "            'virginica', 'virginica', 'virginica', 'virginica'\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "This structure was used with purpose - as a lead up to this exact notebook, where we will use this table-like structure to create a Pandas `DataFrame`. But first, let's discuss one more representation of this data, using a list of dictionaries:\n",
    "\n",
    "```python\n",
    "iris_dataset = [\n",
    "    { 'septal_length' : 4.4, 'sepal_width' : 3.0, 'petal_length' : 1.3, 'petal_width' : 0.2, 'species' : 'setosa' },\n",
    "    { 'septal_length' : 5.1, 'sepal_width' : 3.4, 'petal_length' : 1.5, 'petal_width' : 0.2, 'species' : 'setosa' },\n",
    "    { 'septal_length' : 5.0, 'sepal_width' : 3.5, 'petal_length' : 1.3, 'petal_width' : 0.3, 'species' : 'setosa' },\n",
    "    { 'septal_length' : 4.5, 'sepal_width' : 2.3, 'petal_length' : 1.3, 'petal_width' : 0.3, 'species' : 'setosa' },\n",
    "    { 'septal_length' : 4.4, 'sepal_width' : 3.2, 'petal_length' : 1.3, 'petal_width' : 0.2, 'species' : 'setosa' },\n",
    "    { 'septal_length' : 5.8, 'sepal_width' : 2.6, 'petal_length' : 4.0, 'petal_width' : 1.2, 'species' : 'versicolor' },\n",
    "    { 'septal_length' : 5.0, 'sepal_width' : 2.3, 'petal_length' : 3.3, 'petal_width' : 1.0, 'species' : 'versicolor' },\n",
    "    { 'septal_length' : 5.6, 'sepal_width' : 2.7, 'petal_length' : 4.2, 'petal_width' : 1.3, 'species' : 'versicolor' },\n",
    "    { 'septal_length' : 5.7, 'sepal_width' : 3.0, 'petal_length' : 4.2, 'petal_width' : 1.2, 'species' : 'versicolor' },\n",
    "    { 'septal_length' : 5.7, 'sepal_width' : 2.9, 'petal_length' : 4.2, 'petal_width' : 1.3, 'species' : 'versicolor' },\n",
    "    { 'septal_length' : 6.3, 'sepal_width' : 3.3, 'petal_length' : 6.0, 'petal_width' : 2.5, 'species' : 'virginica' },\n",
    "    { 'septal_length' : 6.8, 'sepal_width' : 3.2, 'petal_length' : 5.9, 'petal_width' : 2.3, 'species' : 'virginica' },\n",
    "    { 'septal_length' : 6.7, 'sepal_width' : 3.3, 'petal_length' : 5.7, 'petal_width' : 2.5, 'species' : 'virginica' },\n",
    "    { 'septal_length' : 6.7, 'sepal_width' : 3.0, 'petal_length' : 5.2, 'petal_width' : 2.3, 'species' : 'virginica' },\n",
    "    { 'septal_length' : 6.3, 'sepal_width' : 2.5, 'petal_length' : 5.0, 'petal_width' : 1.9, 'species' : 'virginica' }   \n",
    "]\n",
    "```\n",
    "\n",
    "Using this structure, we are using the top-level structure (the outer-most `list`) to encapsulate rows, each represented by a dictionary. \n",
    "\n",
    "**Let's now begin with Pandas.**\n",
    "\n",
    "The convention is to import pandas with an alias of `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8398e14-7541-4bd8-866c-f9d6675bed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1090478e-afc8-4655-a291-2dd1e72ee18b",
   "metadata": {},
   "source": [
    "and, to name the `DataFrame` as `df` or if multiple DataFrame's exist, prefix them with `df_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74066dd7-b225-48d5-a24b-2cf357113826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19233d64-5e2c-4251-b368-c89f16f5a816",
   "metadata": {},
   "source": [
    "Okay, we have created an empty DataFrame. This is not particularly insightful, so let's use the data structures from above.\n",
    "\n",
    "The structure used in this example is called *list orientation* (dictionary of lists):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e1652-bf4b-48e5-9e44-416b734c7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = {\n",
    "    'sepal_length' : [4.4, 5.1, 5.0, 4.5, 4.4, 5.8, 5.0, 5.6, 5.7, 5.7, 6.3, 6.8, 6.7, 6.7, 6.3],\n",
    "    'sepal_width' : [3.0, 3.4, 3.5, 2.3, 3.2, 2.6, 2.3, 2.7, 3.0, 2.9, 3.3, 3.2, 3.3, 3.0, 2.5],\n",
    "    'petal_length' : [1.3, 1.5, 1.3, 1.3, 1.3, 4.0, 3.3, 4.2, 4.2, 4.2, 6.0, 5.9, 5.7, 5.2, 5.0],\n",
    "    'petal_width' : [0.2, 0.2, 0.3, 0.3, 0.2, 1.2, 1.0, 1.3, 1.2, 1.3, 2.5, 2.3, 2.5, 2.3, 1.9],\n",
    "    'species' : [\n",
    "            'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'versicolor', \n",
    "            'versicolor', 'versicolor', 'versicolor', 'versicolor', 'virginica', \n",
    "            'virginica', 'virginica', 'virginica', 'virginica'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(iris_dataset)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbd3ce4-8ebb-48b1-8201-691587b3a3b9",
   "metadata": {},
   "source": [
    "Great! Notice that when a DataFrame is printed, the columns and rows and printed much nicer than if we were to print the `iris_dataset` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61afd2f-86e1-40eb-97e9-334511188a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f785060-ec32-4480-9f68-6b92fb38a1f9",
   "metadata": {},
   "source": [
    "Now, by using *records orientation* (list of dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47234c03-2b9a-4c58-b3ae-1734ed021672",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = [\n",
    "    { 'septal_length' : 4.4, 'sepal_width' : 3.0, 'petal_length' : 1.3, 'petal_width' : 0.2, 'species' : 'setosa' },\n",
    "    { 'septal_length' : 5.1, 'sepal_width' : 3.4, 'petal_length' : 1.5, 'petal_width' : 0.2, 'species' : 'setosa' },\n",
    "    { 'septal_length' : 5.0, 'sepal_width' : 3.5, 'petal_length' : 1.3, 'petal_width' : 0.3, 'species' : 'setosa' },\n",
    "    { 'septal_length' : 4.5, 'sepal_width' : 2.3, 'petal_length' : 1.3, 'petal_width' : 0.3, 'species' : 'setosa' },\n",
    "    { 'septal_length' : 4.4, 'sepal_width' : 3.2, 'petal_length' : 1.3, 'petal_width' : 0.2, 'species' : 'setosa' },\n",
    "    { 'septal_length' : 5.8, 'sepal_width' : 2.6, 'petal_length' : 4.0, 'petal_width' : 1.2, 'species' : 'versicolor' },\n",
    "    { 'septal_length' : 5.0, 'sepal_width' : 2.3, 'petal_length' : 3.3, 'petal_width' : 1.0, 'species' : 'versicolor' },\n",
    "    { 'septal_length' : 5.6, 'sepal_width' : 2.7, 'petal_length' : 4.2, 'petal_width' : 1.3, 'species' : 'versicolor' },\n",
    "    { 'septal_length' : 5.7, 'sepal_width' : 3.0, 'petal_length' : 4.2, 'petal_width' : 1.2, 'species' : 'versicolor' },\n",
    "    { 'septal_length' : 5.7, 'sepal_width' : 2.9, 'petal_length' : 4.2, 'petal_width' : 1.3, 'species' : 'versicolor' },\n",
    "    { 'septal_length' : 6.3, 'sepal_width' : 3.3, 'petal_length' : 6.0, 'petal_width' : 2.5, 'species' : 'virginica' },\n",
    "    { 'septal_length' : 6.8, 'sepal_width' : 3.2, 'petal_length' : 5.9, 'petal_width' : 2.3, 'species' : 'virginica' },\n",
    "    { 'septal_length' : 6.7, 'sepal_width' : 3.3, 'petal_length' : 5.7, 'petal_width' : 2.5, 'species' : 'virginica' },\n",
    "    { 'septal_length' : 6.7, 'sepal_width' : 3.0, 'petal_length' : 5.2, 'petal_width' : 2.3, 'species' : 'virginica' },\n",
    "    { 'septal_length' : 6.3, 'sepal_width' : 2.5, 'petal_length' : 5.0, 'petal_width' : 1.9, 'species' : 'virginica' }   \n",
    "]\n",
    "\n",
    "df = pd.DataFrame(iris_dataset)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3338a7-846b-4c78-a2b1-7d9df5c4f5a7",
   "metadata": {},
   "source": [
    "The same result! Great.\n",
    "\n",
    "However, there are some differences when using these two approaches.\n",
    "\n",
    "**List orientation *versus* records orientation**\n",
    "\n",
    "For *list orientation* (dictionary of lists):\n",
    "* All lists must be of equal length. Otherwise, an error will be thrown.\n",
    "\n",
    "For *records orientation* (list of dictionaries):\n",
    "* Not all \"rows\" need to contain the same set of columns. If a row is a missing a value for a column, it will be automatically filled with a missing field indicator.\n",
    "\n",
    "Run the following examples to see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327dfab2-fcf0-45de-9d63-116cc6e80615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from https://en.wikipedia.org/wiki/State_of_Origin_series#Interstate_&_International\n",
    "state_of_origin_international_interstate_venues = [\n",
    "   {'Venue': 'Melbourne Cricket Ground (MCG)', 'City': 'Melbourne', 'State': 'Victoria', 'Country': 'Australia', 'No. of games': 5, 'Highest crowd': 91513, 'Lowest crowd': 25105 },\n",
    "   {'Venue': 'Docklands Stadium', 'City': 'Melbourne', 'State': 'Victoria', 'Country': 'Australia', 'No. of games': 3, 'Highest crowd': 56021, 'Lowest crowd': 50967 },\n",
    "   {'Venue': 'Optus Stadium', 'City': 'Perth', 'State': 'Western Australia', 'Country': 'Australia', 'No. of games': 2, 'Highest crowd': 59721, 'Lowest crowd': 59358 },\n",
    "    \n",
    "   # the next three records are missing `Lowest crowd`\n",
    "   {'Venue': 'Olympic Park Stadium', 'City': 'Melbourne', 'State': 'Victoria', 'Country': 'Australia', 'No. of games': 1, 'Highest crowd': 25800 },\n",
    "   {'Venue': 'Veterans Memorial Stadium', 'City': 'Long Beach', 'State': 'California', 'Country': 'United States', 'No. of games': 1, 'Highest crowd': 12439 },\n",
    "   {'Venue': 'Adelaide Oval', 'City': 'Adelaide', 'State': 'South Australia', 'Country': 'Australia', 'No. of games': 1, 'Highest crowd': 25218 }\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(state_of_origin_international_interstate_venues)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78d837-1564-4a89-9926-cd310a207ff5",
   "metadata": {},
   "source": [
    "Again, but using *list orientation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4447ec6-76fc-4e1a-ac71-9c4b7f8dbcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_of_origin_international_interstate_venues = {\n",
    "    'Venue': ['Melbourne Cricket Ground (MCG)', 'Docklands Stadium', 'Optus Stadium', 'Olympic Park Stadium', 'Veterans Memorial Stadium', 'Adelaide Oval'],\n",
    "    'City': ['Melbourne', 'Melbourne', 'Perth', 'Melbourne', 'Long Beach', 'Adelaide'],\n",
    "    'State': ['Victoria', 'Victoria', 'Western Australia', 'Victoria', 'California', 'South Australia'],\n",
    "    'Country': ['Australia', 'Australia', 'Australia', 'Australia', 'United States', 'Australia'],\n",
    "    'No. of games': [5, 3, 2, 1, 1, 1],\n",
    "    'Highest crowd': [91513, 56021, 59721, 25800, 12439, 25218],\n",
    "    \n",
    "    # this list is too short\n",
    "    'Lowest crowd': [25105, 50967, 59358]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(state_of_origin_international_interstate_venues)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80b3fc-b931-49ea-8556-a15bcb5005a7",
   "metadata": {},
   "source": [
    "To fix this, we can fill the shorter list with `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7809828-2ad0-48df-85f5-99049822403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_of_origin_international_interstate_venues = {\n",
    "    'Venue': ['Melbourne Cricket Ground (MCG)', 'Docklands Stadium', 'Optus Stadium', 'Olympic Park Stadium', 'Veterans Memorial Stadium', 'Adelaide Oval'],\n",
    "    'City': ['Melbourne', 'Melbourne', 'Perth', 'Melbourne', 'Long Beach', 'Adelaide'],\n",
    "    'State': ['Victoria', 'Victoria', 'Western Australia', 'Victoria', 'California', 'South Australia'],\n",
    "    'Country': ['Australia', 'Australia', 'Australia', 'Australia', 'United States', 'Australia'],\n",
    "    'No. of games': [5, 3, 2, 1, 1, 1],\n",
    "    'Highest crowd': [91513, 56021, 59721, 25800, 12439, 25218],\n",
    "    \n",
    "    # filled with None\n",
    "    'Lowest crowd': [25105, 50967, 59358, None, None, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(state_of_origin_international_interstate_venues)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee48aca3-c510-4b5b-aa0b-97d242d2603d",
   "metadata": {},
   "source": [
    "## Importing data using the Pandas `pd.read_` functions\n",
    "\n",
    "Pandas supports many methods of initialising a DataFrame with data. Using the search query `read_` in the reference manual found [54 results](https://pandas.pydata.org/docs/search.html?q=read_) for me. The first twenty are particularly interesting:\n",
    "\n",
    "```\n",
    "pandas.read_clipboard\n",
    "pandas.read_csv\n",
    "pandas.read_excel\n",
    "pandas.read_feather\n",
    "pandas.read_fwf\n",
    "pandas.read_gbq\n",
    "pandas.read_hdf\n",
    "pandas.read_html\n",
    "pandas.read_json\n",
    "pandas.read_orc\n",
    "pandas.read_parquet\n",
    "pandas.read_pickle\n",
    "pandas.read_sas\n",
    "pandas.read_spss\n",
    "pandas.read_sql\n",
    "pandas.read_sql_query\n",
    "pandas.read_sql_table\n",
    "pandas.read_stata\n",
    "pandas.read_table\n",
    "pandas.read_xml\n",
    "```\n",
    "\n",
    "We will discuss `read_csv`, `read_html` and `read_json`. Once you have understood the concept of a few, the rest should come naturally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9bcadc-aa83-4f4a-b575-85b3e0898831",
   "metadata": {},
   "source": [
    "**Importing CSV data as a Panda DataFrame**\n",
    "\n",
    "The `read_csv` function can read from many sources and interpret various character delimited formats. The arguments of `read_csv` are:\n",
    "* `filepath`: the location of the CSV file. This can be a local file, a HTTP address, [FTP](https://en.wikipedia.org/wiki/File_Transfer_Protocol) address or from a storage bucket like [AWS S3](https://en.wikipedia.org/wiki/Amazon_S3)\n",
    "* `sep`: the separator (delimiter) to split the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a91bfb5-3211-4707-9618-07adbe14ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://gist.githubusercontent.com/jaidevd/23aef12e9bf56c618c41/raw/c05e98672b8d52fa0cb94aad80f75eb78342e5d4/books_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f3c5e-32ee-4dc4-a6d3-5c838a529e2a",
   "metadata": {},
   "source": [
    "Given we have loaded a CSV from the internet, let's first inspect the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636db15-2548-491a-9886-f56f37917086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the column labels?\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e689c9-e8b9-4073-a61d-21d6b539e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows and columns?\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4ae46-6b9f-47fa-99f5-665a0b2f4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first ten records\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda44265-939c-4f0f-a7f9-640034945c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the last ten records\n",
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919774a-9d3e-40ea-b693-df30fdae0bac",
   "metadata": {},
   "source": [
    "**Importing a table from a webpage as a Panda DataFrame**\n",
    "\n",
    "The `read_html` function can interpret the webpage of any website, when given a HTTP URL. If there exists many tables on the page, then every table will be converted to a DataFrame. A list of DataFrame's will be provided in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3303fc2-565e-4d55-aa0e-c9e4295fa169",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.read_html('https://en.wikipedia.org/wiki/List_of_cities_in_Australia_by_population')\n",
    "\n",
    "print(f'Read the Wikipedia article \"List of cities in Australia by population\"')\n",
    "\n",
    "print(f'Found {len(dfs)} tables on the page.')\n",
    "\n",
    "for df in dfs:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7c9fd-95a3-4b1f-8d44-c2174ed149b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the time of writing, the first table is \"Greater capital city statistical areas by population\"\n",
    "df = dfs[0]\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e26a3f-241b-4137-ae94-d8bcd5d75a10",
   "metadata": {},
   "source": [
    "**Importing JSON data as a Pandas DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f582867-d24e-48bc-a5f0-d78ee21d4085",
   "metadata": {},
   "source": [
    "Let's import the AFL 2022 data. It is JSON formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1b7ee-93f9-4c20-8f1d-f615e6aaca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('https://fixturedownload.com/feed/json/afl-2022')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f3275-38c8-451c-a05c-b115ba3c71d8",
   "metadata": {},
   "source": [
    "### ‚úç Activity 1: load the entire iris dataset\n",
    "\n",
    "You have already seen the iris dataset throughout the unit, but we have usually worked with just a subset of the full dataset.\n",
    "\n",
    "Using this URL, load the data into a DataFrame: https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\n",
    "\n",
    "* How did you know which `read_` function to use?\n",
    "* What columns does it contain?\n",
    "* How many records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6a7bf6-7ff4-48d6-8a10-eaeaa10c94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e653d-68c4-4963-94bd-ddb746c13ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a few sentences here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ecc54-feb2-42dd-b32b-08a224cea4bf",
   "metadata": {},
   "source": [
    "### ‚úç Activity 2: tell us about the Taxi's dataset\n",
    "\n",
    "Load the dataset from: https://raw.githubusercontent.com/mwaskom/seaborn-data/master/taxis.csv\n",
    "\n",
    "* How did you know which `read_` function to use?\n",
    "* What columns does it contain?\n",
    "* How many records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcadaea-baac-4f58-816f-76dd305f5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b1438-1c4e-4270-a831-02d97b8e5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a few sentences here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2472590d-1ad0-4cc9-97fa-ea9f435041d0",
   "metadata": {},
   "source": [
    "## Exporting data with the Pandas `pd.to_` functions\n",
    "\n",
    "Like the `read_` functions, there exist a set of functions to exporting DataFrame's to other formats. \n",
    "\n",
    "For each `read_` function, there is an associated `to_` function.\n",
    "\n",
    "Some formats will also export the *index* of the DataFrame (more about indexes later). \n",
    "By default, the index is the record number (row number).\n",
    "Perhaps, you do not want to export the index. \n",
    "To avoid exporting the index, set `index=False` within the `.to_` function.\n",
    "\n",
    "The first positional argument of the `to_` functions is the filepath to write to. If you have already opened a file handler (using `open()`) then you  can also pass this directly into the function:\n",
    "\n",
    "\n",
    "**Exporting as CSV**\n",
    "\n",
    "```python\n",
    "with open('export.csv', 'w') as fp:\n",
    "    df.to_csv(fp)\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```python\n",
    "df.to_csv('export.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ccac2f-31c5-4a90-8b21-c18f093340e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the Australian cities table from Wikipedia again\n",
    "\n",
    "dfs = pd.read_html('https://en.wikipedia.org/wiki/List_of_cities_in_Australia_by_population')\n",
    "\n",
    "# At the time of writing, the first table is \"Greater capital city statistical areas by population\"\n",
    "df = dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7d397-698b-4f0a-a453-ef0a0c00f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the index\n",
    "print(df.to_csv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b213aab-46e6-4a6b-b0ff-f57a2ad292ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21546834-c2b8-4e78-84a5-1f7245a3a6b2",
   "metadata": {},
   "source": [
    "Can you see the difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4224857-320d-46d9-aa96-06cdf4ee7f33",
   "metadata": {},
   "source": [
    "### ‚úç Activity 3: write the Australian cities table as a CSV to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfaa281-b67f-4f37-95f3-267fae3572b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2bde0-d0c9-4057-992a-ba4b3b71abf4",
   "metadata": {},
   "source": [
    "**Exporting as JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95912ec3-5523-4636-9c62-45d61adfc1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a183d0d-a02c-46ce-80ab-035bb3ef04ef",
   "metadata": {},
   "source": [
    "### ‚úç Activity 4: write the Australian cities table as JSON to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a61b0bd-b4e8-4920-9f21-8fdecc93f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb532d-c547-4c05-9bae-c3bd2b39b08a",
   "metadata": {},
   "source": [
    "**Exporting as Markdown**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ad082-aed2-4e34-ab41-002f618ec5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output from this may line-wrap. If it does, temporarily zoom out (CTRL and 'minus' -)\n",
    "print(df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ada4a-e1c1-4337-a161-13a7bc1740b9",
   "metadata": {},
   "source": [
    "### ‚úç Activity 5: export the DataFrame as a native Python data structure\n",
    "\n",
    "**Export using `.to_dict`**\n",
    "\n",
    "The function `.to_dict()` will export a DataFrame into a Python data structure. \n",
    "\n",
    "There exist many *orientations*. We have already mentioned *list orientation* and *records orientation*. Check out the orientations [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html).\n",
    "\n",
    "In the cells below, export the Australian cities DataFrame in various structures. Make use of the `type()` function to observe the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664999f5-be6a-45bf-b601-d52121990f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to export as `dict` orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d502287-b51e-4444-a08a-86a19dd2de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to export as `list` orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b422ac9-a074-4016-84e7-d47c65933f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to export as `records` orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601cd467-b155-42ff-8f3e-dedcf689bafe",
   "metadata": {},
   "source": [
    "### ‚úç Activity 6: update the column names\n",
    "\n",
    "The `columns` attribute of a DataFrame can be updated:\n",
    "    \n",
    "```python\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```python\n",
    "df.columns = ['Column one', 'Column two', ...]\n",
    "```\n",
    "\n",
    "Update the columns of the Australian cities DataFrame to shorter names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336a04f-7a0a-4c8c-88b6-9e96dbe17172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
